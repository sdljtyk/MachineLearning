# K-近邻算法（分类）

## 基本思路
1. 存在一个具有标签的样本数据集，即了解每一个样本与分类的对应关系；
2. 输入没有标签的新样本之后
   - 计算新数据与样本数据集中每条数据的距离
   - 根据距离，选择前k个最相似的数据
3. 选择k个数据中出现次数最多的分类，作为新数据的分类。

## 特点
* 优点: 精度高、对异常值不敏感、无数据输入假定
* 缺点：计算复杂度高、空间复杂度高
* 使用数据范围： 数值和标称

## 一般流程
1. 收集数据 ：可以使用任何方法
2. 准备数据 : 距离计算所需要的数值，最好是结构化
3. 分析数据 : 可以使用任何方法
4. 训练算法 ：不适用K-近邻算法
5. 测试算法 ：计算错误率
6. 使用算法 ：首先需要输入样本数据和结构化的输出结果，然后运行Ｋ－近邻算法判定输入数据属于哪个分类，最后执行后续处理.

## 小结
> k-近邻算法是分类数据最简单最有效的算法，本章通过两个例子讲述了如何使用k-近邻算法构造分类器。k-近邻算法是基于实例的学习，使用算法时我们必须有接近实际数据的训练样本数据。k-近邻算法必须保存全部数据集，如果训练数据集的很大，必须使用大量的存储空间。此外，由于必须对数据集中的每个数据计算距离值，实际使用时可能非常耗时。  

> k-近邻算法的另一个缺陷是它无法给出任何数据的基础结构信息，因此我们也无法知晓平均实例样本和典型实例样本具有什么特征。